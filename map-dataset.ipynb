{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# config, generator, discriminator, dataset done\n# utils, train to do","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#config\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nTRAIN_DIR = '../input/pix2pix-dataset/'\nVAL_DIR = '../input/pix2pix-dataset/'\nLEARNING_RATE = 2e-4\nBATCH_SIZE = 16\nNUM_WORKERS = 2\nIMAGE_SIZE = 256\nCHANNELS_IMG = 3\nL1_LAMBDA = 100\nLAMBDA_GP = 10\nNUM_EPOCHS = 100\nLOAD_MODEL = False\nSAVE_MODEL =  False\nCHECKPOINT_DISC = './discriminator'\nCHECKPOINT_GEN = './generator'\n\nboth_transform = A.Compose([A.Resize(width=256, height=256)], additional_targets={'image0':'image'})\ntransform_only_input = A.Compose([A.HorizontalFlip(0.5),\n                                  A.ColorJitter(p=0.2),\n                                  A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5],max_pixel_value=255.0),\n                                 ToTensorV2()])\ntransform_only_mask = A.Compose([A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5], max_pixel_value=255.0),\n                                ToTensorV2()])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T12:13:16.546765Z","iopub.execute_input":"2022-04-02T12:13:16.547554Z","iopub.status.idle":"2022-04-02T12:13:16.558282Z","shell.execute_reply.started":"2022-04-02T12:13:16.547503Z","shell.execute_reply":"2022-04-02T12:13:16.557254Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# dataset\nimport numpy as np\nfrom PIL import Image\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import save_image\n\n\nclass MapDataSet(Dataset):\n    def __init__(self, path):\n        self.path = path\n        self.list_files = os.listdir(self.path)\n        \n    def __len__(self):\n        return len(self.list_files)\n    \n    def __getitem__(self, index):\n        img_file = self.list_files[index]\n        img_path = os.path.join(self.path, img_file)\n        image = np.array(Image.open(img_path))\n        input_image = image[:, :600, :]\n        target_image = image[:, 600:, :]\n        \n        augmentations = both_transform(image=input_image, image0=target_image)\n        input_image = augmentations['image']\n        target_image = augmentations['image0']\n        \n        input_image = transform_only_input(image=input_image)['image']\n        target_image = transform_only_mask(image=target_image)['image']\n        \n        return input_image, target_image\n        \nif __name__ == '__main__':\n    dataset = MapDataSet('../input/pix2pix-dataset/maps/maps/train')\n    loader = DataLoader(dataset, batch_size=5)\n    for x, y in loader:\n        print(x.shape)\n        save_image(x, 'x.png')\n        save_image(y, 'y.png')\n        import sys\n        sys.exit()\n      \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T12:13:16.984073Z","iopub.execute_input":"2022-04-02T12:13:16.984643Z","iopub.status.idle":"2022-04-02T12:13:17.306628Z","shell.execute_reply.started":"2022-04-02T12:13:16.984594Z","shell.execute_reply":"2022-04-02T12:13:17.305474Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"torch.Size([5, 3, 256, 256])\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"],"ename":"SystemExit","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Discriminator\n# concatenated x and y because the input and output images are combined in a single image\n# also, that's why inp_channels*2 in Conv2d layer\nimport torch \nimport torch.nn as nn\nclass CNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels,stride=2):\n        super(CNNBlock, self).__init__()\n        self.conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding=1, padding_mode='reflect'),\n        nn.BatchNorm2d(out_channels),\n        nn.LeakyReLU(0.2))\n        \n    def forward(self, x):\n        return self.conv(x)\n    \nclass Discriminator(nn.Module):\n    \n    def __init__(self, in_channels, features=[64,128,256,512]): #256 -> 30x30\n        super().__init__()\n        self.initial = nn.Sequential(\n        nn.Conv2d(in_channels*2,features[0], kernel_size=4, stride=2, padding=1, padding_mode='reflect'),\n        nn.LeakyReLU(0.2)\n        )\n        \n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(\n                CNNBlock(in_channels, feature, stride=1 if feature==features[-1] else 2),\n            )\n            in_channels = feature\n            \n        layers.append(\n            nn.Conv2d(\n                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n            ),\n        )\n        self.model = nn.Sequential(*layers)    \n    \n    def forward(self, x, y):\n        x = torch.cat([x,y], dim=1)\n        x = self.initial(x)\n        return self.model(x)\n    \ndef test():\n    x = torch.randn((1, 3, 256, 256))\n    y = torch.randn((1, 3, 256, 256))\n    model = Discriminator(in_channels=3)\n    preds = model(x, y)\n    print(model)\n    print(preds.shape)\n\n\nif __name__ == \"__main__\":\n    test()\n    \n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-02T12:13:09.864056Z","iopub.execute_input":"2022-04-02T12:13:09.864361Z","iopub.status.idle":"2022-04-02T12:13:10.111348Z","shell.execute_reply.started":"2022-04-02T12:13:09.864328Z","shell.execute_reply":"2022-04-02T12:13:10.110437Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Discriminator(\n  (initial): Sequential(\n    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n    (1): LeakyReLU(negative_slope=0.2)\n  )\n  (model): Sequential(\n    (0): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (1): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (2): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n  )\n)\ntorch.Size([1, 1, 30, 30])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generator\n\n# Similar to UNet\n# down specifies downward part of UNet\n# Encoder LeakyReLU, decoder ReLU\n# dont use batchnorm in initial layer\n# bias=False because we are using BatchNorm\n# output image of init has dimensions 128, as (n-f+2p/s)+1 => (256-4+2)/2 + 1 => 128\n\nimport torch \nimport torch.nn as nn\n\nclass Block(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, act='relu', use_dropout=False):\n        super(Block, self).__init__()\n        self.conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect')\n        if down\n        else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU() if act =='relu' else nn.LeakyReLU(0.2),   \n        )\n        \n        self.use_dropout = use_dropout\n        self.dropout = nn.Dropout(0.5)\n        self.down = down\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return self.dropout(x) if self.use_dropout else x\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=3, features=64):\n        super().__init__()\n        self.initial_down = nn.Sequential(\n            nn.Conv2d(in_channels,features, 4, 2, 1, padding_mode='reflect' ),\n            nn.LeakyReLU(0.2))\n        self.down1 = Block(features, features*2, down=True, act='leaky', use_dropout=False) #64x64\n        self.down2 = Block(features*2, features*4, down=True, act='leaky', use_dropout=False) #32x32\n        self.down3 = Block(features*4, features*8, down=True, act='leaky', use_dropout=False) #16x16\n        self.down4 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #8x8\n        self.down5 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #4x4\n        self.down6 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #2x2\n        \n        self.bottleneck = nn.Sequential(nn.Conv2d(features*8, features*8, 4, 2, 1), nn.ReLU()) #1x1\n        \n        self.up1 = Block(features*8, features*8, down=False, act='relu', use_dropout=True)\n        self.up2 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up3 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up4 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up5 = Block(features*8*2, features*4, down=False, act='relu', use_dropout=True)\n        self.up6 = Block(features*4*2, features*2, down=False, act='relu', use_dropout=True)\n        self.up7 = Block(features*2*2, features, down=False, act='relu', use_dropout=True)\n        self.final_up = nn.Sequential(nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),)\n        \n    def forward(self, x):\n        d1 = self.initial_down(x)\n        d2 = self.down1(d1)\n        d3 = self.down2(d2)\n        d4 = self.down3(d3)\n        d5 = self.down4(d4)\n        d6 = self.down5(d5)\n        d7 = self.down6(d6)\n        bottleneck = self.bottleneck(d7)\n        up1 = self.up1(bottleneck)\n        up2 = self.up2(torch.cat([up1, d7], 1))\n        up3 = self.up3(torch.cat([up2, d6], 1))\n        up4 = self.up4(torch.cat([up3, d5], 1))\n        up5 = self.up5(torch.cat([up4, d4], 1))\n        up6 = self.up6(torch.cat([up5, d3], 1))\n        up7 = self.up7(torch.cat([up6, d2], 1))\n        return self.final_up(torch.cat([up7, d1], 1))\ndef test():\n    x = torch.randn((1, 3, 256, 256))\n    model = Generator(in_channels=3, features=64)\n    preds = model(x)\n    print(preds.shape)\n\n\nif __name__ == \"__main__\":\n    test()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T12:13:11.419730Z","iopub.execute_input":"2022-04-02T12:13:11.420400Z","iopub.status.idle":"2022-04-02T12:13:12.474183Z","shell.execute_reply.started":"2022-04-02T12:13:11.420350Z","shell.execute_reply":"2022-04-02T12:13:12.473363Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generator\n# Similar to UNet\n# down specifies downward part of UNet\n# Encoder LeakyReLU, decoder ReLU\n# dont use batchnorm in initial layer\n# bias=False because we are using BatchNorm\n# output image of init has dimensions 128, as (n-f+2p/s)+1 => (256-4+2)/2 + 1 => 128\n\nimport torch \nimport torch.nn as nn\n\nclass Block(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, act='relu', use_dropout=False):\n        super(Block, self).__init__()\n        self.conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect')\n        if down\n        else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU() if act =='relu' else nn.LeakyReLU(0.2),   \n        )\n        \n        self.use_dropout = use_dropout\n        self.dropout = nn.Dropout(0.5)\n        self.down = down\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return self.dropout(x) if self.use_dropout else x\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=3, features=64):\n        super().__init__()\n        self.initial_down = nn.Sequential(\n            nn.Conv2d(in_channels,features, 4, 2, 1, padding_mode='reflect' ),\n            nn.LeakyReLU(0.2))\n        self.down1 = Block(features, features*2, down=True, act='leaky', use_dropout=False) #64x64\n        self.down2 = Block(features*2, features*4, down=True, act='leaky', use_dropout=False) #32x32\n        self.down3 = Block(features*4, features*8, down=True, act='leaky', use_dropout=False) #16x16\n        self.down4 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #8x8\n        self.down5 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #4x4\n        self.down6 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #2x2\n        \n        self.bottleneck = nn.Sequential(nn.Conv2d(features*8, features*8, 4, 2, 1), nn.ReLU()) #1x1\n        \n        self.up1 = Block(features*8, features*8, down=False, act='relu', use_dropout=True)\n        self.up2 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up3 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up4 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up5 = Block(features*8*2, features*4, down=False, act='relu', use_dropout=True)\n        self.up6 = Block(features*4*2, features*2, down=False, act='relu', use_dropout=True)\n        self.up7 = Block(features*2*2, features, down=False, act='relu', use_dropout=True)\n        self.final_up = nn.Sequential(nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),)\n        \n    def forward(self, x):\n        d1 = self.initial_down(x)\n        d2 = self.down1(d1)\n        d3 = self.down2(d2)\n        d4 = self.down3(d3)\n        d5 = self.down4(d4)\n        d6 = self.down5(d5)\n        d7 = self.down6(d6)\n        bottleneck = self.bottleneck(d7)\n        up1 = self.up1(bottleneck)\n        up2 = self.up2(torch.cat([up1, d7], 1))\n        up3 = self.up3(torch.cat([up2, d6], 1))\n        up4 = self.up4(torch.cat([up3, d5], 1))\n        up5 = self.up5(torch.cat([up4, d4], 1))\n        up6 = self.up6(torch.cat([up5, d3], 1))\n        up7 = self.up7(torch.cat([up6, d2], 1))\n        return self.final_up(torch.cat([up7, d1], 1))\ndef test():\n    x = torch.randn((1, 3, 256, 256))\n    model = Generator(in_channels=3, features=64)\n    preds = model(x)\n    print(preds.shape)\n\n\nif __name__ == \"__main__\":\n    test()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:26:59.824412Z","iopub.execute_input":"2022-04-02T08:26:59.824758Z","iopub.status.idle":"2022-04-02T08:27:00.446810Z","shell.execute_reply.started":"2022-04-02T08:26:59.824723Z","shell.execute_reply":"2022-04-02T08:27:00.445769Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}