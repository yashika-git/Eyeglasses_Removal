{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#config\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nconfig = {\n'DEVICE' : 'cuda',\n'TRAIN_DIR' :  '../input/pix2pix-dataset/maps/maps/train',\n'VAL_DIR' : '../input/pix2pix-dataset/maps/maps/val',\n'LEARNING_RATE' : 2e-4,\n'BATCH_SIZE' : 16,\n'NUM_WORKERS' : 2,\n'IMAGE_SIZE' : 256,\n'CHANNELS_IMG' : 3,\n'L1_LAMBDA' : 100,\n'LAMBDA_GP' : 10,\n'NUM_EPOCHS' : 100,\n'LOAD_MODEL' : False,\n'SAVE_MODEL' :  False,\n'CHECKPOINT_DISC' : './discriminator',\n'CHECKPOINT_GEN' : './generator'}\n\nboth_transform = A.Compose([A.Resize(width=256, height=256)], additional_targets={'image0':'image'})\ntransform_only_input = A.Compose([A.HorizontalFlip(0.5),\n                                  A.ColorJitter(p=0.2),\n                                  A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5],max_pixel_value=255.0),\n                                 ToTensorV2()])\ntransform_only_mask = A.Compose([A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5], max_pixel_value=255.0),\n                                ToTensorV2()])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:16:32.670285Z","iopub.execute_input":"2022-04-02T18:16:32.671004Z","iopub.status.idle":"2022-04-02T18:16:32.680233Z","shell.execute_reply.started":"2022-04-02T18:16:32.670969Z","shell.execute_reply":"2022-04-02T18:16:32.679513Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# dataset\nimport numpy as np\nfrom PIL import Image\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import save_image\n\n\nclass MapDataSet(Dataset):\n    def __init__(self, path):\n        self.path = path\n        self.list_files = os.listdir(path)\n            \n    def __len__(self):\n        return len(self.list_files)\n     \n    def __getitem__(self, index):\n        img_file = self.list_files[index]\n        img_path = os.path.join(self.path, img_file)\n        image = np.array(Image.open(img_path))\n        input_image = image[:, :600, :]\n        target_image = image[:, 600:, :]\n        \n        augmentations = both_transform(image=input_image, image0=target_image)\n        input_image = augmentations['image']\n        target_image = augmentations['image0']\n        \n        input_image = transform_only_input(image=input_image)['image']\n        target_image = transform_only_mask(image=target_image)['image']\n        \n        return input_image, target_image\n        \nif __name__ == '__main__':\n    dataset = MapDataSet('../input/pix2pix-dataset/maps/maps/train')\n    loader = DataLoader(dataset, batch_size=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:16:33.667831Z","iopub.execute_input":"2022-04-02T18:16:33.668357Z","iopub.status.idle":"2022-04-02T18:16:33.683007Z","shell.execute_reply.started":"2022-04-02T18:16:33.668319Z","shell.execute_reply":"2022-04-02T18:16:33.682207Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Discriminator\n# concatenated x and y because the input and output images are combined in a single image\n# also, that's why inp_channels*2 in Conv2d layer\nimport torch \nimport torch.nn as nn\nclass CNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels,stride=2):\n        super(CNNBlock, self).__init__()\n        self.conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding=1, padding_mode='reflect'),\n        nn.BatchNorm2d(out_channels),\n        nn.LeakyReLU(0.2))\n        \n    def forward(self, x):\n        return self.conv(x)\n    \nclass Discriminator(nn.Module):\n    \n    def __init__(self, in_channels, features=[64,128,256,512]): #256 -> 30x30\n        super().__init__()\n        self.initial = nn.Sequential(\n        nn.Conv2d(in_channels*2,features[0], kernel_size=4, stride=2, padding=1, padding_mode='reflect'),\n        nn.LeakyReLU(0.2)\n        )\n        \n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(\n                CNNBlock(in_channels, feature, stride=1 if feature==features[-1] else 2),\n            )\n            in_channels = feature\n            \n        layers.append(\n            nn.Conv2d(\n                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n            ),\n        )\n        self.model = nn.Sequential(*layers)    \n    \n    def forward(self, x, y):\n        x = torch.cat([x,y], dim=1)\n        x = self.initial(x)\n        return self.model(x)\n    \ndef test():\n    x = torch.randn((1, 3, 256, 256))\n    y = torch.randn((1, 3, 256, 256))\n    model = Discriminator(in_channels=3)\n    preds = model(x, y)\n    print(model)\n    print(preds.shape)\n\n\nif __name__ == \"__main__\":\n    test()\n    \n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-04-02T18:16:34.823803Z","iopub.execute_input":"2022-04-02T18:16:34.824394Z","iopub.status.idle":"2022-04-02T18:16:34.993318Z","shell.execute_reply.started":"2022-04-02T18:16:34.824354Z","shell.execute_reply":"2022-04-02T18:16:34.992522Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Discriminator(\n  (initial): Sequential(\n    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n    (1): LeakyReLU(negative_slope=0.2)\n  )\n  (model): Sequential(\n    (0): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (1): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (2): CNNBlock(\n      (conv): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n    )\n    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n  )\n)\ntorch.Size([1, 1, 30, 30])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generator\n\n# Similar to UNet\n# down specifies downward part of UNet\n# Encoder LeakyReLU, decoder ReLU\n# dont use batchnorm in initial layer\n# bias=False because we are using BatchNorm\n# output image of init has dimensions 128, as (n-f+2p/s)+1 => (256-4+2)/2 + 1 => 128\n\nimport torch \nimport torch.nn as nn\n\nclass Block(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, act='relu', use_dropout=False):\n        super(Block, self).__init__()\n        self.conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect')\n        if down\n        else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU() if act =='relu' else nn.LeakyReLU(0.2),   \n        )\n        \n        self.use_dropout = use_dropout\n        self.dropout = nn.Dropout(0.5)\n        self.down = down\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return self.dropout(x) if self.use_dropout else x\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=3, features=64):\n        super().__init__()\n        self.initial_down = nn.Sequential(\n            nn.Conv2d(in_channels,features, 4, 2, 1, padding_mode='reflect' ),\n            nn.LeakyReLU(0.2))\n        self.down1 = Block(features, features*2, down=True, act='leaky', use_dropout=False) #64x64\n        self.down2 = Block(features*2, features*4, down=True, act='leaky', use_dropout=False) #32x32\n        self.down3 = Block(features*4, features*8, down=True, act='leaky', use_dropout=False) #16x16\n        self.down4 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #8x8\n        self.down5 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #4x4\n        self.down6 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #2x2\n        \n        self.bottleneck = nn.Sequential(nn.Conv2d(features*8, features*8, 4, 2, 1), nn.ReLU()) #1x1\n        \n        self.up1 = Block(features*8, features*8, down=False, act='relu', use_dropout=True)\n        self.up2 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up3 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up4 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n        self.up5 = Block(features*8*2, features*4, down=False, act='relu', use_dropout=True)\n        self.up6 = Block(features*4*2, features*2, down=False, act='relu', use_dropout=True)\n        self.up7 = Block(features*2*2, features, down=False, act='relu', use_dropout=True)\n        self.final_up = nn.Sequential(nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),)\n        \n    def forward(self, x):\n        d1 = self.initial_down(x)\n        d2 = self.down1(d1)\n        d3 = self.down2(d2)\n        d4 = self.down3(d3)\n        d5 = self.down4(d4)\n        d6 = self.down5(d5)\n        d7 = self.down6(d6)\n        bottleneck = self.bottleneck(d7)\n        up1 = self.up1(bottleneck)\n        up2 = self.up2(torch.cat([up1, d7], 1))\n        up3 = self.up3(torch.cat([up2, d6], 1))\n        up4 = self.up4(torch.cat([up3, d5], 1))\n        up5 = self.up5(torch.cat([up4, d4], 1))\n        up6 = self.up6(torch.cat([up5, d3], 1))\n        up7 = self.up7(torch.cat([up6, d2], 1))\n        return self.final_up(torch.cat([up7, d1], 1))\ndef test():\n    x = torch.randn((1, 3, 256, 256))\n    model = Generator(in_channels=3, features=64)\n    preds = model(x)\n    print(preds.shape)\n\n\nif __name__ == \"__main__\":\n    test()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:16:35.478217Z","iopub.execute_input":"2022-04-02T18:16:35.478601Z","iopub.status.idle":"2022-04-02T18:16:36.261961Z","shell.execute_reply.started":"2022-04-02T18:16:35.478563Z","shell.execute_reply":"2022-04-02T18:16:36.261160Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"# utils\nimport torch\nfrom torchvision.utils import save_image\n\ndef save_some_examples(gen, val_loader, epoch, folder):\n    x, y =next(iter(val_loader))\n    x, y = x.to(config['DEVICE']), y.to(config['DEVICE'])\n    gen.eval()\n    with torch.no_grad():\n        y_fake = gen(x)\n        y_fake = y_fake * 0.5 + 0.5 #removing normalization\n        save_image(y_fake, folder + f'/y_gen_{epoch}.png')\n        if epoch == 1:\n            save_image(y * 0.5 + 0.5, folder + f'/label_{epoch}.png' )\n    gen.train()        \n        \ndef save_checkpoint(model, optimizer, filename='my_checkpoint.pth.tar'):\n    print('=> Saving Checkpoint')\n    checkpoint = {\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict()\n    }\n    torch.save(checkpoint, filename)\n    \ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print('=> Loading checkpoint')\n    checkpoint = torch.load(checkpoint_file, map_location=config['DEVICE'])\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    \n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:20:23.160842Z","iopub.execute_input":"2022-04-02T18:20:23.161116Z","iopub.status.idle":"2022-04-02T18:20:23.172330Z","shell.execute_reply.started":"2022-04-02T18:20:23.161087Z","shell.execute_reply":"2022-04-02T18:20:23.170978Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# train\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torchvision.utils import save_image\ntorch.backends.cudnn.benchmark = True\n\ndef train_fn(disc, gen, loader, opt_disc,opt_gen, l1_loss, bce, g_scaler, d_scaler):\n    loop = tqdm(loader, leave=True)\n    \n    for idx, (x,y) in enumerate(loop):\n        x = x.to(config['DEVICE'])\n        y = y.to(config['DEVICE'])\n        \n        #Train Discriminator\n        with torch.cuda.amp.autocast():\n            y_fake = gen(x)\n            D_real = disc(x,y)\n            D_real_loss = bce(D_real, torch.ones_like(D_real))\n            D_fake = disc(x, y_fake.detach())\n            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n            D_loss = (D_real_loss + D_fake_loss)/2            \n    \n        disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n        \n        #Train Generator\n        with torch.cuda.amp.autocast():\n            D_fake = disc(x, y_fake)\n            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n            L1 = l1_loss(y_fake, y)*(config['L1_LAMBDA'])\n            G_loss = G_fake_loss + L1\n            \n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n        \n        if idx % 10 == 0:\n            loop.set_postfix(\n            D_real=torch.sigmoid(D_real).mean().item(),\n            D_fake=torch.sigmoid(D_fake).mean().item())        \n\ndisc = Discriminator(in_channels=3).to(config['DEVICE'])\ngen = Generator(in_channels=3, features=64).to(config['DEVICE'])\nopt_disc = optim.Adam(disc.parameters(), lr=config['LEARNING_RATE'], betas=(0.5, 0.999))\nopt_gen = optim.Adam(gen.parameters(), lr=config['LEARNING_RATE'], betas=(0.5, 0.999))\nBCE = nn.BCEWithLogitsLoss()\nL1_LOSS = nn.L1Loss()\n\nif config['LOAD_MODEL']:\n    load_checkpoint(config['CHECKPOINT_GEN'], gen, opt_gen, config['LEARNING_RATE'])\n    load_checkpoint(config['CHECKPOINT_DISC'], disc, opt_disc, config['LEARNING_RATE'])\n\ntrain_dataset = MapDataSet(path=config['TRAIN_DIR'])\ntrain_loader = DataLoader( train_dataset, batch_size=config['BATCH_SIZE'], shuffle=True, num_workers=config['NUM_WORKERS'])\ng_scaler = torch.cuda.amp.GradScaler()\nd_scaler = torch.cuda.amp.GradScaler()\nval_dataset = MapDataSet(path=config['VAL_DIR'])\nval_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n\nfor epoch in range(config['NUM_EPOCHS']):\n    train_fn(disc, gen, train_loader,opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler)\n    if config['SAVE_MODEL'] and epoch % 5 == 0:\n        save_checkpoint(gen, opt_gen, filename=config['CHECKPOINT_GEN'])\n        save_checkpoint(disc, opt_disc, filename=config['CHECKPOINT_DISC'])\n    save_some_examples(gen, val_loader, config['NUM_EPOCHS'], folder='./')    \n        \n       ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:26:25.434034Z","iopub.execute_input":"2022-04-02T18:26:25.434290Z","iopub.status.idle":"2022-04-02T19:09:07.746776Z","shell.execute_reply.started":"2022-04-02T18:26:25.434261Z","shell.execute_reply":"2022-04-02T19:09:07.745934Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.119, D_real=0.745]\n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0615, D_real=0.936]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0126, D_real=0.943]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0709, D_real=0.752]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.316, D_real=0.88] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.068, D_real=0.653] \n100%|██████████| 69/69 [00:25<00:00,  2.67it/s, D_fake=0.205, D_real=0.488] \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.19, D_real=0.702]  \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0855, D_real=0.83] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.521, D_real=0.243] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.108, D_real=0.921] \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.363, D_real=0.512] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.169, D_real=0.684] \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.135, D_real=0.964]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.167, D_real=0.97]  \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.119, D_real=0.844] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0448, D_real=0.958]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.209, D_real=0.982] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.193, D_real=0.732] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.1, D_real=0.851]   \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0525, D_real=0.822]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0636, D_real=0.955]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0801, D_real=0.892]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.372, D_real=0.337] \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.609, D_real=0.343] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.293, D_real=0.854] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.189, D_real=0.751] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0363, D_real=0.988]\n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.028, D_real=0.974] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0389, D_real=0.882]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.147, D_real=0.531] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.259, D_real=0.934] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0187, D_real=0.975]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0475, D_real=0.953]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.106, D_real=0.982] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.319, D_real=0.72]  \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.032, D_real=0.837] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0709, D_real=0.836]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0634, D_real=0.856]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.267, D_real=0.722] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0422, D_real=0.969]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.128, D_real=0.994] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0565, D_real=0.916] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.637, D_real=0.619] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0111, D_real=0.955]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0117, D_real=0.995]\n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0482, D_real=0.958] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0311, D_real=0.957]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.156, D_real=0.989] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0385, D_real=0.915]\n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.0352, D_real=0.872]\n100%|██████████| 69/69 [00:25<00:00,  2.66it/s, D_fake=0.248, D_real=0.829] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0499, D_real=0.94]  \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.479, D_real=0.685]  \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.065, D_real=0.966]  \n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.0743, D_real=0.924]\n100%|██████████| 69/69 [00:25<00:00,  2.66it/s, D_fake=0.0201, D_real=0.999]\n100%|██████████| 69/69 [00:25<00:00,  2.67it/s, D_fake=0.168, D_real=0.94]  \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0335, D_real=0.876] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.31, D_real=0.646]  \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0243, D_real=0.998]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0174, D_real=0.938]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0677, D_real=0.987]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0357, D_real=0.972]\n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.0188, D_real=0.996]\n100%|██████████| 69/69 [00:25<00:00,  2.67it/s, D_fake=0.0279, D_real=0.985]\n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.22, D_real=0.354]   \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.044, D_real=0.998] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0773, D_real=0.983]\n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0395, D_real=0.98] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0458, D_real=0.999]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.11, D_real=0.986]  \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.0238, D_real=0.816]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.035, D_real=0.93]    \n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.033, D_real=0.999]  \n100%|██████████| 69/69 [00:25<00:00,  2.67it/s, D_fake=0.00164, D_real=0.994]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.0105, D_real=0.96] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0303, D_real=0.769] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0141, D_real=0.953] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.00503, D_real=0.858]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.148, D_real=0.176] \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.00475, D_real=0.975]\n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.115, D_real=0.872] \n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.0292, D_real=0.915]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0406, D_real=0.975]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0418, D_real=0.956] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0128, D_real=0.861] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.019, D_real=0.861] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.053, D_real=0.946] \n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.144, D_real=0.982] \n100%|██████████| 69/69 [00:25<00:00,  2.69it/s, D_fake=0.0703, D_real=0.962]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0149, D_real=0.986]\n100%|██████████| 69/69 [00:25<00:00,  2.73it/s, D_fake=0.0252, D_real=1]     \n100%|██████████| 69/69 [00:25<00:00,  2.68it/s, D_fake=0.00832, D_real=0.994]\n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.00763, D_real=0.986]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0152, D_real=0.96]  \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0376, D_real=0.901] \n100%|██████████| 69/69 [00:25<00:00,  2.72it/s, D_fake=0.0126, D_real=0.989]\n100%|██████████| 69/69 [00:25<00:00,  2.70it/s, D_fake=0.0532, D_real=0.954] \n100%|██████████| 69/69 [00:25<00:00,  2.71it/s, D_fake=0.105, D_real=0.791]   \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}