{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport torch.optim as optim\nfrom torchvision.utils import save_image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom PIL import Image, ImageOps\nimport time\n\ntrain = pd.read_csv('../input/glasses-or-no-glasses/train.csv')\ntest = pd.read_csv('../input/glasses-or-no-glasses/test.csv')\ntrain.set_index('id', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:01:52.570018Z","iopub.execute_input":"2022-04-23T11:01:52.570766Z","iopub.status.idle":"2022-04-23T11:01:56.965502Z","shell.execute_reply.started":"2022-04-23T11:01:52.570644Z","shell.execute_reply":"2022-04-23T11:01:56.964783Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# configs \nBATCH_SIZE = 1\nLAMBDA_IDENTITY = 0.0\nLEARNING_RATE = 2e-4\nNUM_EPOCHS = 2\nLAMBDA_CYCLE = 10 \nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:01:56.967225Z","iopub.execute_input":"2022-04-23T11:01:56.967483Z","iopub.status.idle":"2022-04-23T11:01:57.029255Z","shell.execute_reply.started":"2022-04-23T11:01:56.967439Z","shell.execute_reply":"2022-04-23T11:01:57.028550Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:01:57.031356Z","iopub.execute_input":"2022-04-23T11:01:57.033026Z","iopub.status.idle":"2022-04-23T11:01:57.048105Z","shell.execute_reply.started":"2022-04-23T11:01:57.032982Z","shell.execute_reply":"2022-04-23T11:01:57.047358Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Output Directories\nresults_NoGlasses = './NoGlasses'\nresults_Glasses = './Glasses'","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:01:57.050363Z","iopub.execute_input":"2022-04-23T11:01:57.050619Z","iopub.status.idle":"2022-04-23T11:01:57.055536Z","shell.execute_reply.started":"2022-04-23T11:01:57.050582Z","shell.execute_reply":"2022-04-23T11:01:57.054724Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# segregating images with and without glasses\ndirectory = '../input/glasses-or-no-glasses/faces-spring-2020/faces-spring-2020'\ntrain_imgs_glasses = []\ntrain_imgs_no_glasses = []\ntest_imgs = []\nfor img in os.listdir(directory):\n    img_id = int(img.replace('face-', ''  ).replace('.png', ''))\n    for i in range(len(train)+1):\n        if (i) == (img_id):\n            if train.loc[img_id]['glasses'] == 0:\n                train_imgs_no_glasses.append(os.path.join(directory, str(img)))\n                break\n                \n            elif train.loc[img_id]['glasses'] == 1:\n                train_imgs_glasses.append(os.path.join(directory, str(img)))\n                break\n                \n        \n    for i in range(len(test)+1): \n        if int(i) == int(img_id):\n            test_imgs.append(os.path.join(directory, str(img)))\n            break         ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:01:57.056819Z","iopub.execute_input":"2022-04-23T11:01:57.057190Z","iopub.status.idle":"2022-04-23T11:02:03.328121Z","shell.execute_reply.started":"2022-04-23T11:01:57.057154Z","shell.execute_reply":"2022-04-23T11:02:03.327414Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(len(train_imgs_glasses))\nprint(len(train_imgs_no_glasses))\nprint(len(test_imgs))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:02:03.329305Z","iopub.execute_input":"2022-04-23T11:02:03.329574Z","iopub.status.idle":"2022-04-23T11:02:03.335222Z","shell.execute_reply.started":"2022-04-23T11:02:03.329538Z","shell.execute_reply":"2022-04-23T11:02:03.334467Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"2856\n1644\n500\n","output_type":"stream"}]},{"cell_type":"code","source":"test_imgs_glasses = train_imgs_glasses[:571]\ntest_imgs_no_glasses = train_imgs_no_glasses[:328]\ntrain_imgs_glasses = train_imgs_glasses[571:]\ntrain_imgs_no_glasses = train_imgs_no_glasses[328:]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:02:03.336521Z","iopub.execute_input":"2022-04-23T11:02:03.337240Z","iopub.status.idle":"2022-04-23T11:02:03.348759Z","shell.execute_reply.started":"2022-04-23T11:02:03.337204Z","shell.execute_reply":"2022-04-23T11:02:03.348056Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, imgs_glasses, imgs_no_glasses, transform = None ):\n        super().__init__()\n        self.root_dir = directory\n        self.glasses_list = imgs_glasses\n        self.no_glasses_list = imgs_no_glasses\n        self.transform = transform\n        \n    def __len__(self):\n        self.glasses_len = len(self.glasses_list)\n        self.no_glasses_len = len(self.no_glasses_list)\n        self.dataset_len = max(self.glasses_len, self.no_glasses_len)\n        return self.dataset_len\n    \n    def __getitem__(self, idx):\n        start_time = time.time()\n        glasses_path = self.glasses_list[idx % self.glasses_len]\n        no_glasses_path = self.no_glasses_list[idx % self.no_glasses_len]\n        img_glasses = np.array(ImageOps.grayscale(Image.open(glasses_path).convert('RGB')))\n        img_no_glasses = np.array(ImageOps.grayscale(Image.open(no_glasses_path).convert('RGB')))\n        \n        if self.transform:\n            augmentation = self.transform(image=img_glasses, image0=img_no_glasses)\n            img_glasses = augmentation[\"image0\"]\n            img_no_glasses = augmentation[\"image\"]\n            \n            \n        end_time = time.time()    \n        print(f\"{end_time - start_time} data loading time\")\n        return img_glasses, img_no_glasses","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:02:03.349913Z","iopub.execute_input":"2022-04-23T11:02:03.350677Z","iopub.status.idle":"2022-04-23T11:02:03.361394Z","shell.execute_reply.started":"2022-04-23T11:02:03.350621Z","shell.execute_reply":"2022-04-23T11:02:03.360612Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transforms_train = A.Compose(\n    [\n        A.Resize(256, 256),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(mean=[0.5], std=[0.5], max_pixel_value=255.0),\n        ToTensorV2()\n    ],\n    additional_targets = {\"image0\":\"image\"}\n)\n\ntransforms_val = A.Compose(\n    [\n        A.Resize(256, 256),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(mean=[0.5], std=[0.5], max_pixel_value=255.0),\n        ToTensorV2()\n    ],\n    additional_targets = {\"image0\":\"image\"}\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:02:03.364197Z","iopub.execute_input":"2022-04-23T11:02:03.364396Z","iopub.status.idle":"2022-04-23T11:02:03.373330Z","shell.execute_reply.started":"2022-04-23T11:02:03.364365Z","shell.execute_reply":"2022-04-23T11:02:03.372483Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Generator\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity()\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\n    \nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channels, channels, kernel_size=3, padding=1),\n            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n    \nclass Generator(nn.Module):\n    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n            nn.InstanceNorm2d(num_features),\n            nn.ReLU(inplace=True),\n        )\n        self.down_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n            ]\n        )\n        self.res_blocks = nn.Sequential(\n            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n        )\n        self.up_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n            ]\n        )\n\n        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n\n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_blocks:\n            x = layer(x)\n        x = self.res_blocks(x)\n        for layer in self.up_blocks:\n            x = layer(x)\n        return torch.tanh(self.last(x))    ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:12:59.009828Z","iopub.execute_input":"2022-04-23T11:12:59.010084Z","iopub.status.idle":"2022-04-23T11:12:59.027148Z","shell.execute_reply.started":"2022-04-23T11:12:59.010052Z","shell.execute_reply":"2022-04-23T11:12:59.026306Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Discriminator\n\nclass Block(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=4,\n                stride=stride,\n                padding=1,\n                bias=True,\n                padding_mode=\"reflect\"\n            ),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2)       \n        )\n        \n    def forward(self, x):\n        return self.conv(x)       \n        \n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n        nn.Conv2d(\n            in_channels,\n            features[0],\n            kernel_size=4,\n            stride=2,\n            padding=1,\n            padding_mode=\"reflect\"\n        ),\n        nn.LeakyReLU(0.2))\n    \n        layers = []\n    \n        in_channels = features[0]\n    \n        for feature in features[1:]:\n            layers.append(\n                Block(in_channels, feature, stride=1 if feature==features[-1] else 2)\n            )\n            in_channels = feature\n        \n        layers.append(\n            nn.Conv2d(\n                in_channels,\n                1,\n                kernel_size=4,\n                stride=1,\n                padding=1,\n                padding_mode=\"reflect\"\n            ))\n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        x = self.initial(x)\n        return torch.sigmoid(self.model(x))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:13:52.222625Z","iopub.execute_input":"2022-04-23T11:13:52.223348Z","iopub.status.idle":"2022-04-23T11:13:52.234105Z","shell.execute_reply.started":"2022-04-23T11:13:52.223305Z","shell.execute_reply":"2022-04-23T11:13:52.233440Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# utility\n\ndef save_some_examples_g(gen, val_loader, epoch, idx, folder):\n    img_glasses, img_no_glasses = next(iter(val_loader))\n    img_glasses, img_no_glasses = img_glasses.to(DEVICE), img_no_glasses.to(DEVICE)\n    gen.eval()\n    with torch.no_grad():\n        y_fake_glasses = gen(img_no_glasses)\n        y_fake_glasses = y_fake_glasses*0.5 + 0.5\n        save_image(y_fake_glasses, os.path.join(folder, f\"{epoch}_{idx}_fake_glasses.png\"))\n\ndef save_some_examples_n(gen, val_loader, epoch, idx, folder):\n    img_glasses, img_no_glasses = next(iter(val_loader))\n    img_glasses, img_no_glasses = img_glasses.to(DEVICE), img_no_glasses.to(DEVICE)\n    gen.eval()\n    with torch.no_grad():\n        y_fake_no_glasses = gen(img_glasses)\n        y_fake_no_glasses = y_fake_no_glasses*0.5 + 0.5\n        save_image(y_fake_no_glasses, os.path.join(folder, f\"{epoch}_{idx}_fake_no_glasses.png\"))\n\ndef save_checkpoint(model, optimizer, epoch, filename):\n    filename = str(epoch) + filename + \"_cpt.pth.tar\"\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n    torch.save(checkpoint, filename)\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading Checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    model.load_state(checkpoint[\"state_dict\"])\n    optimizer.load_state(checkpoint[\"state_dict\"])\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:15:17.280074Z","iopub.execute_input":"2022-04-23T11:15:17.280508Z","iopub.status.idle":"2022-04-23T11:15:17.298110Z","shell.execute_reply.started":"2022-04-23T11:15:17.280459Z","shell.execute_reply":"2022-04-23T11:15:17.297438Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# train\ndef trainFn(disc_G, disc_N, gen_G, gen_N, loader, optim_g, optim_d, l1, mse, val_loader, epoch):\n    loop = tqdm(loader)\n    for idx, (img_glasses, img_no_glasses) in enumerate(loop):\n        img_glasses = img_glasses.to(DEVICE)\n        img_no_glasses = img_no_glasses.to(DEVICE)\n        \n        fake_no_glasses = gen_N(img_glasses)\n        disc_ng_real = disc_N(img_no_glasses)\n        disc_ng_fake = disc_N(fake_no_glasses.detach())\n        disc_ng_real_loss = mse(disc_ng_real, torch.ones_like(disc_ng_real))\n        disc_ng_fake_loss = mse(disc_ng_fake, torch.zeros_like(disc_ng_fake))\n        disc_ng_loss = disc_ng_fake_loss + disc_ng_real_loss\n            \n        \n        fake_glasses = gen_G(img_no_glasses)\n        disc_g_real = disc_G(img_glasses)\n        disc_g_fake = disc_G(fake_glasses.detach())\n        disc_g_real_loss = mse(disc_g_real, torch.ones_like(disc_g_real))\n        disc_g_fake_loss = mse(disc_g_fake, torch.zeros_like(disc_g_fake))\n        disc_g_loss = disc_g_real_loss + disc_g_fake_loss\n        \n        #total disc loss\n        D_loss = (disc_ng_loss + disc_g_loss)/2\n        \n        # backprop and update the weights of discriminator\n        optim_d.zero_grad()\n        D_loss.backward()\n        optim_d.step()\n        \n        # Training Generators\n        \n        # Adversarial loss\n        disc_g_fake = disc_G(fake_glasses)\n        disc_ng_fake = disc_N(fake_no_glasses)\n        loss_g_glasses = mse(disc_g_fake, torch.ones_like(disc_g_fake))\n        loss_g_no_glasses = mse(disc_ng_fake, torch.ones_like(disc_ng_fake))\n        \n        # Cycle loss\n        cycle_glasses = gen_G(fake_no_glasses)\n        cycle_no_glasses = gen_N(fake_glasses)\n        glasses_cycle_loss = l1(img_glasses, cycle_glasses)\n        no_glasses_cycle_loss = l1(img_no_glasses, cycle_no_glasses)\n    \n        \n        # Total Generator Loss\n        G_loss = (loss_g_glasses + loss_g_no_glasses) + LAMBDA_CYCLE*(glasses_cycle_loss + no_glasses_cycle_loss) #+ loss_pccl \n        \n        # backprop and updating weights of Generator\n        optim_g.zero_grad()\n        G_loss.backward()\n        optim_g.step()\n        \n        print(f\"Generator loss: {G_loss}, Discriminator loss: {D_loss}\")\n        save_some_examples_n(gen_N, val_loader, epoch, idx, folder=results_NoGlasses)\n        save_some_examples_g(gen_G, val_loader, epoch, idx, folder=results_Glasses)\n        \n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:15:18.335383Z","iopub.execute_input":"2022-04-23T11:15:18.335634Z","iopub.status.idle":"2022-04-23T11:15:18.347570Z","shell.execute_reply.started":"2022-04-23T11:15:18.335603Z","shell.execute_reply":"2022-04-23T11:15:18.346518Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\n# Instantiating Generators and Discriminators\ndisc_G = Discriminator(in_channels=1).to(DEVICE)\ndisc_N = Discriminator(in_channels=1).to(DEVICE)\ngen_G = Generator(img_channels=1).to(DEVICE)\ngen_N = Generator(img_channels=1).to(DEVICE)\n\n# Initializing optimizers\nopt_disc = optim.Adam(list(disc_G.parameters()) + list(disc_N.parameters()), lr=LEARNING_RATE, betas=(0.5, 0.999))\nopt_gen = optim.Adam(list(gen_G.parameters()) + list(gen_N.parameters()), lr = LEARNING_RATE, betas=(0.5, 0.999))\n\n# Loss Function\nL1 = nn.L1Loss()\nmse = nn.MSELoss()\n\n# Dataset Instantiation\ntrain_data = Dataset(imgs_glasses=train_imgs_glasses, imgs_no_glasses=train_imgs_no_glasses, transform=transforms_train)\nval_data = Dataset(imgs_glasses=test_imgs_glasses, imgs_no_glasses=test_imgs_no_glasses, transform = transforms_val )\n\n# Dataloaders\ntrain_loader = DataLoader(train_data, BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_data, BATCH_SIZE, shuffle=False)\n\n# Training Loop\nfor epoch in range(NUM_EPOCHS):\n    print(f\"Epoch: {epoch}\")\n    trainFn(disc_G, disc_N, gen_G, gen_N, train_loader, opt_gen, opt_disc, L1, mse, val_loader, epoch)\n    \n    save_checkpoint(disc_G, opt_disc, epoch, \"disc_G\")\n    save_checkpoint(disc_N, opt_disc, epoch, \"disc_N\")\n    save_checkpoint(gen_G, opt_gen, epoch, \"gen_G\")\n    save_checkpoint(gen_N, opt_gen, epoch, \"gen_N\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:16:21.026609Z","iopub.execute_input":"2022-04-23T11:16:21.027056Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch: 0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/2285 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"0.16737055778503418 data loading time\nGenerator loss: 9.636834144592285, Discriminator loss: 0.5181452631950378\n0.10380029678344727 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/2285 [00:00<35:06,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"0.10062909126281738 data loading time\n0.16440296173095703 data loading time\nGenerator loss: 10.559904098510742, Discriminator loss: 0.5904992818832397\n0.09866619110107422 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 2/2285 [00:01<34:59,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"0.11269474029541016 data loading time\n0.23880577087402344 data loading time\nGenerator loss: 7.788736820220947, Discriminator loss: 0.6042899489402771\n0.09550189971923828 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 3/2285 [00:02<35:33,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"0.09573984146118164 data loading time\n0.17225098609924316 data loading time\nGenerator loss: 7.388592720031738, Discriminator loss: 0.5931902527809143\n0.09428143501281738 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 4/2285 [00:03<35:06,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"0.09922981262207031 data loading time\n0.22643065452575684 data loading time\nGenerator loss: 5.607796669006348, Discriminator loss: 0.5427411794662476\n0.12799429893493652 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 5/2285 [00:04<36:41,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"0.14174318313598633 data loading time\n0.18082141876220703 data loading time\nGenerator loss: 8.032356262207031, Discriminator loss: 0.5348354578018188\n0.09430336952209473 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 6/2285 [00:05<35:44,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"0.09578728675842285 data loading time\n0.15385103225708008 data loading time\nGenerator loss: 6.04660701751709, Discriminator loss: 0.5049116611480713\n0.10097932815551758 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 7/2285 [00:06<34:49,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"0.09369206428527832 data loading time\n0.287426233291626 data loading time\nGenerator loss: 4.986987590789795, Discriminator loss: 0.5568957328796387\n0.09352874755859375 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 8/2285 [00:07<35:45,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"0.09362387657165527 data loading time\n0.19965863227844238 data loading time\nGenerator loss: 5.650547981262207, Discriminator loss: 0.5405142307281494\n0.09700703620910645 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 9/2285 [00:08<35:21,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"0.09518909454345703 data loading time\n0.17090702056884766 data loading time\nGenerator loss: 5.005168437957764, Discriminator loss: 0.548236072063446\n0.09480428695678711 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 10/2285 [00:09<34:42,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"0.09401202201843262 data loading time\n0.1868276596069336 data loading time\nGenerator loss: 5.269892692565918, Discriminator loss: 0.46102797985076904\n0.09452199935913086 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 11/2285 [00:10<34:24,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"0.09380912780761719 data loading time\n0.15676093101501465 data loading time\nGenerator loss: 6.363898754119873, Discriminator loss: 0.5156164169311523\n0.09647130966186523 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 12/2285 [00:11<33:54,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09611010551452637 data loading time\n0.1606295108795166 data loading time\nGenerator loss: 6.165931701660156, Discriminator loss: 0.5174157619476318\n0.09431695938110352 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 13/2285 [00:11<33:34,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.09408187866210938 data loading time\n0.1962718963623047 data loading time\nGenerator loss: 5.890685558319092, Discriminator loss: 0.538612961769104\n0.09939455986022949 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 14/2285 [00:12<34:17,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"0.12359213829040527 data loading time\n0.22403931617736816 data loading time\nGenerator loss: 4.561140537261963, Discriminator loss: 0.5534608364105225\n0.09446310997009277 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 15/2285 [00:13<34:32,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"0.0940701961517334 data loading time\n0.16665935516357422 data loading time\nGenerator loss: 4.996186256408691, Discriminator loss: 0.5180983543395996\n0.09760761260986328 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 16/2285 [00:14<34:07,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"0.09660744667053223 data loading time\n0.1832742691040039 data loading time\nGenerator loss: 3.642618417739868, Discriminator loss: 0.5389069318771362\n0.09518623352050781 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 17/2285 [00:15<33:57,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"0.09512042999267578 data loading time\n0.1472470760345459 data loading time\nGenerator loss: 5.978096961975098, Discriminator loss: 0.5367153882980347\n0.10076045989990234 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 18/2285 [00:16<33:35,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.0992887020111084 data loading time\n0.16298294067382812 data loading time\nGenerator loss: 4.941512107849121, Discriminator loss: 0.5103596448898315\n0.09604072570800781 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 19/2285 [00:17<33:21,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.09424376487731934 data loading time\n0.15998601913452148 data loading time\nGenerator loss: 5.742105484008789, Discriminator loss: 0.4916642904281616\n0.09464240074157715 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 20/2285 [00:18<33:08,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.09437203407287598 data loading time\n0.1872711181640625 data loading time\nGenerator loss: 4.306693077087402, Discriminator loss: 0.4898461103439331\n0.09789919853210449 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 21/2285 [00:19<33:17,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.0930781364440918 data loading time\n0.1751396656036377 data loading time\nGenerator loss: 5.637331962585449, Discriminator loss: 0.4943039119243622\n0.10100245475769043 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 22/2285 [00:19<33:19,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.09577512741088867 data loading time\n0.19021058082580566 data loading time\nGenerator loss: 6.25470495223999, Discriminator loss: 0.4629901647567749\n0.0968637466430664 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 23/2285 [00:20<33:47,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.12185835838317871 data loading time\n0.1466982364654541 data loading time\nGenerator loss: 3.5696966648101807, Discriminator loss: 0.49820002913475037\n0.10512137413024902 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 24/2285 [00:21<33:21,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.0936729907989502 data loading time\n0.1643223762512207 data loading time\nGenerator loss: 5.090057849884033, Discriminator loss: 0.53089439868927\n0.09714365005493164 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 25/2285 [00:22<33:10,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.0933225154876709 data loading time\n0.1424548625946045 data loading time\nGenerator loss: 3.4620935916900635, Discriminator loss: 0.5352891683578491\n0.09527873992919922 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 26/2285 [00:23<32:48,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.09764695167541504 data loading time\n0.15478825569152832 data loading time\nGenerator loss: 5.996757984161377, Discriminator loss: 0.5008090734481812\n0.14030075073242188 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 27/2285 [00:24<33:33,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.1156914234161377 data loading time\n0.17083406448364258 data loading time\nGenerator loss: 5.918813705444336, Discriminator loss: 0.4994276762008667\n0.09962630271911621 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 28/2285 [00:25<33:23,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.0939626693725586 data loading time\n0.14322423934936523 data loading time\nGenerator loss: 5.641182899475098, Discriminator loss: 0.48347651958465576\n0.09352684020996094 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 29/2285 [00:26<32:54,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.09535551071166992 data loading time\n0.13810491561889648 data loading time\nGenerator loss: 3.661992311477661, Discriminator loss: 0.5103164315223694\n0.10162019729614258 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 30/2285 [00:26<32:36,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.09484028816223145 data loading time\n0.19214987754821777 data loading time\nGenerator loss: 5.209482669830322, Discriminator loss: 0.48476195335388184\n0.0937645435333252 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 31/2285 [00:27<32:53,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.09397220611572266 data loading time\n0.14749693870544434 data loading time\nGenerator loss: 3.667834758758545, Discriminator loss: 0.4514615535736084\n0.09883689880371094 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 32/2285 [00:28<32:41,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.09804773330688477 data loading time\n0.15672516822814941 data loading time\nGenerator loss: 6.570411205291748, Discriminator loss: 0.5328554511070251\n0.09663128852844238 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 33/2285 [00:29<32:35,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.0954899787902832 data loading time\n0.1504368782043457 data loading time\nGenerator loss: 3.480137348175049, Discriminator loss: 0.5182355642318726\n0.0970304012298584 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 34/2285 [00:30<32:30,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.09892630577087402 data loading time\n0.16118097305297852 data loading time\nGenerator loss: 3.3863420486450195, Discriminator loss: 0.5044739246368408\n0.09501481056213379 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 35/2285 [00:31<32:28,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.09431719779968262 data loading time\n0.10139775276184082 data loading time\nGenerator loss: 3.9542479515075684, Discriminator loss: 0.48139411211013794\n0.09886956214904785 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 36/2285 [00:32<31:50,  1.18it/s]","output_type":"stream"},{"name":"stdout","text":"0.0970604419708252 data loading time\n0.1843428611755371 data loading time\nGenerator loss: 4.912776947021484, Discriminator loss: 0.47963160276412964\n0.09936165809631348 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 37/2285 [00:33<32:21,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"0.09705328941345215 data loading time\n0.15622186660766602 data loading time\nGenerator loss: 5.24446439743042, Discriminator loss: 0.48225080966949463\n0.09515810012817383 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 38/2285 [00:33<32:27,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"0.10642504692077637 data loading time\n0.17737770080566406 data loading time\nGenerator loss: 8.629812240600586, Discriminator loss: 0.5107936859130859\n0.1048429012298584 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 39/2285 [00:34<32:51,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.09471821784973145 data loading time\n0.23175048828125 data loading time\nGenerator loss: 3.7778706550598145, Discriminator loss: 0.4519962668418884\n0.10074591636657715 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 40/2285 [00:35<33:38,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"0.09807968139648438 data loading time\n0.15716838836669922 data loading time\nGenerator loss: 4.74644136428833, Discriminator loss: 0.4810718297958374\n0.09639692306518555 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 41/2285 [00:36<33:16,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09675192832946777 data loading time\n0.1915750503540039 data loading time\nGenerator loss: 4.273990631103516, Discriminator loss: 0.46902936697006226\n0.1267414093017578 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 42/2285 [00:37<34:23,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"0.13802671432495117 data loading time\n0.19128775596618652 data loading time\nGenerator loss: 5.0306396484375, Discriminator loss: 0.5020711421966553\n0.09588813781738281 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 43/2285 [00:38<34:06,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"0.09355473518371582 data loading time\n0.15404844284057617 data loading time\nGenerator loss: 3.6666014194488525, Discriminator loss: 0.5689402222633362\n0.09421086311340332 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 44/2285 [00:39<33:27,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09353518486022949 data loading time\n0.19503211975097656 data loading time\nGenerator loss: 4.199084281921387, Discriminator loss: 0.47446006536483765\n0.09521150588989258 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 45/2285 [00:40<33:28,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09519386291503906 data loading time\n0.1846909523010254 data loading time\nGenerator loss: 4.019532203674316, Discriminator loss: 0.4816747307777405\n0.09811019897460938 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 46/2285 [00:41<33:24,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09554028511047363 data loading time\n0.16846156120300293 data loading time\nGenerator loss: 5.159547805786133, Discriminator loss: 0.4240516722202301\n0.09938478469848633 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 47/2285 [00:42<33:10,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"0.09459900856018066 data loading time\n0.16440153121948242 data loading time\nGenerator loss: 3.329651355743408, Discriminator loss: 0.5192723274230957\n0.09706783294677734 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 48/2285 [00:42<32:58,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.09649658203125 data loading time\n0.17954039573669434 data loading time\nGenerator loss: 5.029185771942139, Discriminator loss: 0.439708411693573\n0.10099601745605469 data loading time\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 49/2285 [00:43<33:01,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"0.09555292129516602 data loading time\n0.19109606742858887 data loading time\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}